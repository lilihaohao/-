{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f70eea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "036141ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type():   \n",
    "    model = lgb.LGBMRegressor(\n",
    "            num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "            max_depth=-1, learning_rate=0.1, min_child_samples=5, random_state=2019,\n",
    "            n_estimators=600, subsample=0.8, colsample_bytree=0.7)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61e7ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(data):\n",
    "    tmp = data.copy()\n",
    "    tmp['weekday'] = tmp['Date_Hour'].map(lambda x: datetime.strptime(str(x), '%Y%m%d%H').weekday()+1)\n",
    "    tmp['month'] = tmp['Date_Hour'].map(lambda x: int((x%2020000000)/10000))\n",
    "    tmp['day'] = tmp['Date_Hour'].map(lambda x: int((x%10000)/100))\n",
    "    tmp['hour'] = tmp['Date_Hour'].map(lambda x: int((x%100)))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26c6a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(train, features, cate_feat):\n",
    "    \n",
    "    begin_data,last_data= 2020020100, 2020020723\n",
    "    data = train.copy()\n",
    "\n",
    "    time_feat = []\n",
    "    data['is_weekday']=data['weekday'].map(lambda x : 1 if x>=6 else 0)\n",
    "    time_feat.append('is_weekday')\n",
    "    data['is_worktime'] = list(map(lambda x,y : 1 if (y<=6) and ( (x>=8 and x<=12) or (x>=14 and x<=18) )  else 0, data['hour'],data['weekday']) )\n",
    "    time_feat.append('is_worktime')\n",
    "    data['is_day'] = data['hour'].map(lambda x:1 if x>=8 and x<=19 else 0)\n",
    "    time_feat.append('is_day')\n",
    "    data['is_night'] = data['hour'].map(lambda x:1 if x>=21 else 0)\n",
    "    data['is_eat'] = data['hour'].map(lambda x:1 if ( x>=7 and x<=9 ) or (x>=12 and x<=13) or (x>=17 and x<=18) else 0)\n",
    "\n",
    "    pivot = pd.pivot_table(data,index=[\"area_type_2\"],values='area',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'area':'mean_area'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\"],how=\"left\")\n",
    "    pivot = pd.pivot_table(data,index=[\"area_type_2\"],values='area',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'area':'min_area'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\"],how=\"left\")   \n",
    "    \n",
    "    pivot = pd.pivot_table(data,index=[\"area_type_2\"],values='area',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'area':'max_area'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\"],how=\"left\")\n",
    "    \n",
    "    features.append('mean_area')\n",
    "    features.append('max_area')\n",
    "    features.append('min_area')\n",
    "\n",
    "    tmp =data[(data['Date_Hour']>=begin_data) & (data['Date_Hour']<=last_data)]\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'hour'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'mean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'hour'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'hour'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'std_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'hour'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'min_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'hour'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'max_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'hour'],how=\"left\")\n",
    "    \n",
    "    features.append('std_Index')\n",
    "    features.append('mean_Index')\n",
    "    features.append('max_Index')\n",
    "    features.append('min_Index')\n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_1\",'hour'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_1mean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_1\",'hour'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_1\",'hour'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_1std_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_1\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_1\",'hour'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_1min_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_1\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_1\",'hour'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_1max_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_1\",'hour'],how=\"left\")\n",
    "    \n",
    "    features.append('area_type_1std_Index')\n",
    "    features.append('area_type_1mean_Index')\n",
    "    features.append('area_type_1max_Index')\n",
    "    features.append('area_type_1min_Index')\n",
    " \n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_2\",'hour'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_2mean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\",'hour'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_2\",'hour'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_2std_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_2\",'hour'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_2min_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\",'hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"area_type_2\",'hour'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'area_type_2max_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"area_type_2\",'hour'],how=\"left\")\n",
    "    \n",
    "    features.append('area_type_2std_Index')\n",
    "    features.append('area_type_2mean_Index')\n",
    "    features.append('area_type_2max_Index')\n",
    "    features.append('area_type_2min_Index')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=['hour'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hourmean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['hour'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=['hour'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hourstd_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=['hour'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hourmin_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=['hour'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hourmax_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['hour'],how=\"left\")\n",
    "    \n",
    "    features.append('hourstd_Index')\n",
    "    features.append('hourmean_Index')\n",
    "    features.append('hourmax_Index')\n",
    "    features.append('hourmin_Index')\n",
    "\n",
    "\n",
    "    day=9\n",
    "    tmp= data.copy()\n",
    "    \n",
    "    tmp['Date_Hour'] = list(map(lambda x:x + day*100 ,tmp['Date_Hour']))\n",
    "    tmp['Date_Hour'] = list(map(lambda x,y: 2020020100+x%100 + (int((x%10000)/100)-32)*100 if int((x%10000)/100)>=32 and y == 1 else x,tmp['Date_Hour'],tmp['month']))\n",
    "    tmp['Date_Hour']  = tmp['Date_Hour'].map(int)\n",
    "    lt = list(set(list(data['Date_Hour'])))\n",
    "    tmp = tmp[tmp['Date_Hour'].isin(lt)][['ID','Date_Hour','Index']]\n",
    "    tmp = tmp.rename(columns={'Index':'last_9_Index'})\n",
    "    data = pd.merge(data,tmp,how='left',on=['ID','Date_Hour'])\n",
    "        \n",
    "    features.append('last_9_Index')\n",
    "    \n",
    "    \n",
    "    day=14\n",
    "    tmp= data.copy()\n",
    "    tmp['Date_Hour'] = list(map(lambda x:x + day*100 ,tmp['Date_Hour']))\n",
    "    tmp['Date_Hour'] = list(map(lambda x,y: 2020020100+x%100 + (int((x%10000)/100)-32)*100 if int((x%10000)/100)>=32 and y == 1 else x,tmp['Date_Hour'],tmp['month']))\n",
    "    tmp['Date_Hour']  = tmp['Date_Hour'].map(int)\n",
    "    lt = list(set(list(data['Date_Hour'])))\n",
    "    tmp = tmp[tmp['Date_Hour'].isin(lt)][['ID','Date_Hour','Index']]\n",
    "    tmp = tmp.rename(columns={'Index':'last_1_Index'})\n",
    "    data = pd.merge(data,tmp,how='left',on=['ID','Date_Hour'])\n",
    "        \n",
    "\n",
    "    \n",
    "    tmp =data[(data['Date_Hour']>=begin_data) & (data['Date_Hour']<=last_data)]\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'weekday'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'weekdaymean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'weekday'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'weekday'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'weekdaystd_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'weekday'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'weekdaymin_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'weekday'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'weekdaymax_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'weekday'],how=\"left\")\n",
    "    \n",
    "    features.append('weekdaystd_Index')\n",
    "    features.append('weekdaymean_Index')\n",
    "    features.append('weekdaymax_Index')\n",
    "    features.append('weekdaymin_Index')\n",
    "    \n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"hour\",'is_weekday'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hour_week_mean_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"hour\",'is_weekday'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"hour\",'is_weekday'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hour_week_std_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"hour\",'is_weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"hour\",'is_weekday'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hour_week_min_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"hour\",'is_weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"hour\",'is_weekday'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'hour_week_max_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"hour\",'is_weekday'],how=\"left\")\n",
    "    \n",
    "    features.append('hour_week_mean_index')\n",
    "    features.append('hour_week_std_index')\n",
    "    features.append('hour_week_min_index')\n",
    "    features.append('hour_week_max_index')\n",
    "    \n",
    "    \n",
    "        \n",
    "    pivot = pd.pivot_table(tmp,index=['is_weekday'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'_week_mean_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['is_weekday'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=['is_weekday'],values='Index',aggfunc=np.std)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'_week_std_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['is_weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=['is_weekday'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'_week_min_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['is_weekday'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=['is_weekday'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'_week_max_index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=['is_weekday'],how=\"left\")\n",
    "        \n",
    "    features.append('_week_mean_index')\n",
    "    features.append('_week_std_index')\n",
    "    features.append('_week_min_index')\n",
    "    features.append('_week_max_index')\n",
    "    \n",
    "    tmp =data[(data['Date_Hour']>=begin_data) & (data['Date_Hour']<=last_data)]\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'is_weekday'],values='Index',aggfunc=np.sum)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'is_week_sum_Index'}).reset_index()\n",
    "    tmp = pd.merge(tmp,pivot,on=['ID','is_weekday'],how='left')\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\"],values='Index',aggfunc=np.sum)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'week_sum_Index'}).reset_index()\n",
    "    tmp = pd.merge(tmp,pivot,on=['ID'],how='left')\n",
    "    tmp['is_week_ratio_week'] = list(map(lambda x,y:0 if y==0 else x/y,tmp['is_week_sum_Index'],tmp['week_sum_Index']))\n",
    "    now_tmp = tmp[['ID','is_weekday','is_week_ratio_week']]\n",
    "    \n",
    "    now_tmp=now_tmp.drop_duplicates()\n",
    "    data  = pd.merge(data,now_tmp,on=[\"ID\",'is_weekday'],how=\"left\")\n",
    "    \n",
    "    features.append('is_week_ratio_week')\n",
    "    \n",
    "    \n",
    "    tmp =data[(data['Date_Hour']>=begin_data) & (data['Date_Hour']<=last_data)]\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'is_weekday','hour'],values='Index',aggfunc=np.mean)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'ID_weekdaymean_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'is_weekday','hour'],how=\"left\")\n",
    "\n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'is_weekday','hour'],values='Index',aggfunc=np.min)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'ID_weekdaymin_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'is_weekday','hour'],how=\"left\")\n",
    "    \n",
    "    pivot = pd.pivot_table(tmp,index=[\"ID\",'is_weekday','hour'],values='Index',aggfunc=np.max)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Index':'ID_weekdaymax_Index'}).reset_index()\n",
    "    data  = pd.merge(data,pivot,on=[\"ID\",'is_weekday','hour'],how=\"left\")\n",
    "    \n",
    "    features = features + time_feat\n",
    "    cate_feat = cate_feat + time_feat\n",
    "    \n",
    "    return data, features, cate_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5efebb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve():\n",
    "    'load data'\n",
    "    info_data = pd.read_csv('area_passenger_info.csv',header=None)\n",
    "    index_data = pd.read_csv('area_passenger_index.csv',header=None)\n",
    "    pred = pd.read_csv('test_submit_example.csv',header=None)\n",
    "    migration_index  = pd.read_csv('migration_index.csv',header=None)\n",
    "    \n",
    "    info_data= info_data.rename(columns={0:'ID',1:'area_name',2:'area_type',3:'Center_x',4:'Center_y',5:'Grid_x',6:'Grid_y',7:'area'})\n",
    "    index_data= index_data.rename(columns={0:'ID',1:'Date_Hour',2:'Index'})\n",
    "    pred= pred.rename(columns={0:'ID',1:'Date_Hour',2:'Index'})\n",
    "    pred['Index'] = np.nan\n",
    "    \n",
    "    tot_index = pd.concat([index_data,pred])\n",
    "    \n",
    "    \n",
    "    migration_index= migration_index.rename(columns={0:'Date_Hour',1:'departure_province',2:'departure_city',3:'arrival__province',4:'arrival_city',5:'index'})\n",
    "    migration_index['out_index']=list(map(lambda x,z:z if x=='北京市' else 0,migration_index['departure_province'],migration_index['index']))\n",
    "    migration_index['in_index']=list(map(lambda x,z:z if x=='北京市' else 0,migration_index['arrival__province'],migration_index['index']))\n",
    "    pivot = pd.pivot_table(migration_index,values=['out_index','in_index'],index=['Date_Hour'],aggfunc=np.sum).reset_index()\n",
    "    pivot['weekday'] = pivot['Date_Hour'].map(lambda x: datetime.strptime(str(x), '%Y%m%d').weekday()+1)\n",
    "    \n",
    "    \n",
    "    tmp = pd.pivot_table(pivot,index=[\"weekday\"],values=['in_index','out_index'],aggfunc=np.mean)\n",
    "    tmp = pd.DataFrame(tmp).rename(columns={'in_index':'week_mean_in_index','out_index':'week_mean_out_index'}).reset_index()\n",
    "    \n",
    "    \n",
    "    tot_index = pre(tot_index)\n",
    "    tot_index  = pd.merge(tot_index,tmp,on=[\"weekday\"],how=\"left\")\n",
    "    data = pd.merge(tot_index,info_data,on=['ID'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    data['area_type_1']=data['area_type'].map(lambda x: str(x).split(\";\")[0])\n",
    "    data['area_type_2']=data['area_type'].map(lambda x: str(x).split(\";\")[1])\n",
    "    \n",
    "    area_type_1 = dict(zip(sorted(list(set(data['area_type_1']))), range(0, len(set(data['area_type_1'])))))\n",
    "    area_type_2 = dict(zip(sorted(list(set(data['area_type_2']))), range(0, len(set(data['area_type_2'])))))\n",
    "    \n",
    "    data['area_type_1']=data['area_type_1'].map(area_type_1)\n",
    "    data['area_type_2']=data['area_type_2'].map(area_type_2)\n",
    "    \n",
    "    data['hour_id'] = data['hour'].map(lambda x:int(x/3))\n",
    "    \n",
    "    tot_data = data.copy()\n",
    "        \n",
    "    \n",
    "    features = ['weekday','month','day','hour','area_type_1','area_type_2','Center_x','Center_y','Grid_x','Grid_y','area']\n",
    "    \n",
    "    features = features +['week_mean_in_index','week_mean_out_index']\n",
    "    cate_feat=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    data, features,cate_feat= get_feature(tot_data,features,cate_feat)\n",
    "    train_data = data[(data['Date_Hour']>=2020020800) & (data['Date_Hour']<=2020021523)]\n",
    "    train_pred = data[(data['Date_Hour']>=2020021600) & (data['Date_Hour']<=2020022423)]\n",
    "    model = get_model_type()\n",
    "    model.fit(train_data[features], train_data['Index'],verbose=1)\n",
    "    train_pred['pred'] = model.predict(train_pred[features])\n",
    "    train_pred['pred'] = train_pred['pred'].map(lambda x:0 if x<0 else x) \n",
    "    sub = train_pred[['ID','Date_Hour','pred']]\n",
    "\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5035cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_1(train, features, cate_feat,day):\n",
    "    \n",
    "    \n",
    "\n",
    "    data = train.copy()\n",
    "    time_feat = []\n",
    "    data['is_weekday']=data['weekday'].map(lambda x : 1 if x>=6 else 0)\n",
    "    time_feat.append('is_weekday')\n",
    "    data['is_worktime'] = list(map(lambda x,y : 1 if (y<=6) and ( (x>=8 and x<=12) or (x>=14 and x<=18) )  else 0, data['hour'],data['weekday']) )\n",
    "    time_feat.append('is_worktime')\n",
    "    data['is_day'] = data['hour'].map(lambda x:1 if x>=8 and x<=19 else 0)\n",
    "    time_feat.append('is_day')\n",
    "    data['is_night'] = data['hour'].map(lambda x:1 if x>=21 else 0)\n",
    "    data['is_eat'] = data['hour'].map(lambda x:1 if ( x>=7 and x<=9 ) or (x>=12 and x<=13) or (x>=17 and x<=18) else 0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    b = day\n",
    "    day=9\n",
    "    tmp= data.copy()\n",
    "    tmp['Date_Hour'] = list(map(lambda x:x + day*100 ,tmp['Date_Hour']))\n",
    "    tmp['Date_Hour'] = list(map(lambda x,y: 2020020100+x%100 + (int((x%10000)/100)-32)*100 if int((x%10000)/100)>=32 and y == 1 else x,tmp['Date_Hour'],tmp['month']))\n",
    "    tmp['Date_Hour']  = tmp['Date_Hour'].map(int)\n",
    "    lt = list(set(list(data['Date_Hour'])))\n",
    "    tmp = tmp[tmp['Date_Hour'].isin(lt)][['ID','Date_Hour','Index']]\n",
    "    tmp = tmp.rename(columns={'Index':'last_9_Index'})\n",
    "    data = pd.merge(data,tmp,how='left',on=['ID','Date_Hour'])\n",
    "\n",
    "    features.append('last_9_Index')\n",
    "    \n",
    "    day=b\n",
    "    day=7\n",
    "    tmp= data.copy()\n",
    "    tmp['Date_Hour'] = list(map(lambda x:x + day*100 ,tmp['Date_Hour']))\n",
    "    tmp['Date_Hour'] = list(map(lambda x,y: 2020020100+x%100 + (int((x%10000)/100)-32)*100 if int((x%10000)/100)>=32 and y == 1 else x,tmp['Date_Hour'],tmp['month']))\n",
    "    tmp['Date_Hour']  = tmp['Date_Hour'].map(int)\n",
    "    lt = list(set(list(data['Date_Hour'])))\n",
    "    tmp = tmp[tmp['Date_Hour'].isin(lt)][['ID','Date_Hour','Index']]\n",
    "    tmp = tmp.rename(columns={'Index':'last_7_Index'})\n",
    "    data = pd.merge(data,tmp,how='left',on=['ID','Date_Hour'])\n",
    "        \n",
    "    features.append('last_7_Index')\n",
    "    \n",
    "\n",
    "        \n",
    "    day=14\n",
    "    tmp= data.copy()\n",
    "    tmp['Date_Hour'] = list(map(lambda x:x + day*100 ,tmp['Date_Hour']))\n",
    "    tmp['Date_Hour'] = list(map(lambda x,y: 2020020100+x%100 + (int((x%10000)/100)-32)*100 if int((x%10000)/100)>=32 and y == 1 else x,tmp['Date_Hour'],tmp['month']))\n",
    "    tmp['Date_Hour']  = tmp['Date_Hour'].map(int)\n",
    "    lt = list(set(list(data['Date_Hour'])))\n",
    "    tmp = tmp[tmp['Date_Hour'].isin(lt)][['ID','Date_Hour','Index']]\n",
    "    tmp = tmp.rename(columns={'Index':'last_14_Index'})\n",
    "    data = pd.merge(data,tmp,how='left',on=['ID','Date_Hour'])\n",
    "        \n",
    "    features.append('last_14_Index')\n",
    "    \n",
    "    \n",
    "    data['diff'] = data['last_7_Index']-data['last_14_Index']\n",
    "    features.append('diff')\n",
    "    \n",
    "    \n",
    "    features = features + time_feat\n",
    "    cate_feat = cate_feat + time_feat\n",
    "    \n",
    "    return data, features, cate_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61ea758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve2():\n",
    "    info_data = pd.read_csv('area_passenger_info.csv',header=None)\n",
    "    index_data = pd.read_csv('area_passenger_index.csv',header=None)\n",
    "    pred = pd.read_csv('test_submit_example.csv',header=None)\n",
    "    migration_index  = pd.read_csv('migration_index.csv',header=None)\n",
    "    \n",
    "    \n",
    "    info_data= info_data.rename(columns={0:'ID',1:'area_name',2:'area_type',3:'Center_x',4:'Center_y',5:'Grid_x',6:'Grid_y',7:'area'})\n",
    "    index_data= index_data.rename(columns={0:'ID',1:'Date_Hour',2:'Index'})\n",
    "    \n",
    "    pred= pred.rename(columns={0:'ID',1:'Date_Hour',2:'Index'})\n",
    "    pred['Index'] = np.nan\n",
    "    \n",
    "    tot_index = pd.concat([index_data,pred])\n",
    "    \n",
    "    \n",
    "    \n",
    "    migration_index= migration_index.rename(columns={0:'Date_Hour',1:'departure_province',2:'departure_city',3:'arrival__province',4:'arrival_city',5:'index'})\n",
    "    migration_index['out_index']=list(map(lambda x,z:z if x=='北京市' else 0,migration_index['departure_province'],migration_index['index']))\n",
    "    migration_index['in_index']=list(map(lambda x,z:z if x=='北京市' else 0,migration_index['arrival__province'],migration_index['index']))\n",
    "    pivot = pd.pivot_table(migration_index,values=['out_index','in_index'],index=['Date_Hour'],aggfunc=np.sum).reset_index()\n",
    "    pivot['weekday'] = pivot['Date_Hour'].map(lambda x: datetime.strptime(str(x), '%Y%m%d').weekday()+1)\n",
    "    \n",
    "    \n",
    "    tmp = pd.pivot_table(pivot,index=[\"weekday\"],values=['in_index','out_index'],aggfunc=np.mean)\n",
    "    tmp = pd.DataFrame(tmp).rename(columns={'in_index':'week_mean_in_index','out_index':'week_mean_out_index'}).reset_index()\n",
    "    \n",
    "    \n",
    "    tot_index = pre(tot_index)\n",
    "    \n",
    "    tot_index  = pd.merge(tot_index,tmp,on=[\"weekday\"],how=\"left\")\n",
    "    \n",
    "    data = pd.merge(tot_index,info_data,on=['ID'])\n",
    "    \n",
    "    data['area_type_1']=data['area_type'].map(lambda x: str(x).split(\";\")[0])\n",
    "    data['area_type_2']=data['area_type'].map(lambda x: str(x).split(\";\")[1])\n",
    "    \n",
    "    area_type_1 = dict(zip(sorted(list(set(data['area_type_1']))), range(0, len(set(data['area_type_1'])))))\n",
    "    area_type_2 = dict(zip(sorted(list(set(data['area_type_2']))), range(0, len(set(data['area_type_2'])))))\n",
    "    \n",
    "    data['area_type_1']=data['area_type_1'].map(area_type_1)\n",
    "    data['area_type_2']=data['area_type_2'].map(area_type_2)\n",
    "    \n",
    "    \n",
    "    use_data = data.copy()\n",
    "    \n",
    "\n",
    "    \n",
    "    out = data[(data['Date_Hour']>=2020021600) & (data['Date_Hour']<=2020022423)][['ID','Date_Hour','Index']]\n",
    "    valid = data[(data['Date_Hour']>=2020020700) & (data['Date_Hour']<=2020021523)]\n",
    "    valid['pred']=-1\n",
    "    \n",
    "    for day in range(1,10):\n",
    "        \n",
    "        features = ['weekday','month','day','hour','area_type_1','area_type_2','Center_x','Center_y','Grid_x','Grid_y','area']\n",
    "        features = features +['week_mean_in_index','week_mean_out_index']\n",
    "        cate_feat =['weekday','month','day','hour','area_type_1','area_type_2'] \n",
    "        data, features,cate_feat= get_feature_1(use_data, features, cate_feat, day)\n",
    "        train_data = data[(data['Date_Hour']>=2020020800) & (data['Date_Hour']<=2020021523)]\n",
    "        train_pred = data[(data['Date_Hour']>=(20200215+day)*100) & (data['Date_Hour']<=(20200215+day)*100+23)]\n",
    "        \n",
    "        model = get_model_type()\n",
    "        model.fit(train_data[features], train_data['Index'],verbose=1)\n",
    "        train_pred['pred'] = model.predict(train_pred[features])\n",
    "        train_pred['pred'] = train_pred['pred'].map(lambda x:0 if x<0 else x) \n",
    "    \n",
    "        out.loc[(out['Date_Hour']>=(20200215+day)*100) & (out['Date_Hour']<=(20200215+day)*100+23),  'Index'] = train_pred['pred'].values\n",
    "        use_data.loc[(use_data['Date_Hour']>=(20200215+day)*100) & (use_data['Date_Hour']<=(20200215+day)*100+23),  'Index'] = train_pred['pred'].values\n",
    "        \n",
    "    sub = out[['ID','Date_Hour','Index']]\n",
    "    \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d13158a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3a9be5f2e1cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LC.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0msolve3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-3a9be5f2e1cf>\u001b[0m in \u001b[0;36msolve3\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msolve3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msub_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msub_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolve2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msub_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.04\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m786\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msub_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msub_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.04\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m786\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.03\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msub_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-b7e19aae5725>\u001b[0m in \u001b[0;36msolve\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date_Hour'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m2020021600\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date_Hour'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m2020022423\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\pycharm\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[0;32m    817\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[0;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\pycharm\\Anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\pycharm\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\pycharm\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2641\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2642\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2643\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def solve3():\n",
    "    sub_1=solve()\n",
    "    sub_2=solve2()\n",
    "    sub_1['pred']= list(map(lambda x,y:x*1.04 if y ==786 else x*1.05,sub_1['pred'] ,sub_1['ID'] ))\n",
    "    sub_2['Index']= list(map(lambda x,y:x*1.04 if y ==786 else x*1.03,sub_2['Index'] ,sub_2['ID'] ))\n",
    "    \n",
    "#    sub_1.to_csv('./result/LC_3.csv',header=None,sep=',',index=False)\n",
    "#    sub_2.to_csv('./result/LC_4.csv',header=None,sep=',',index=False)\n",
    "   \n",
    "    sub_1['Index'] = sub_2['Index']\n",
    "    sub_1['Pred'] = sub_1['Index']*0.50 + sub_1['pred']*0.50\n",
    "    out = sub_1[['ID','Date_Hour','Pred']]\n",
    "    out.loc[(out['Date_Hour']>=2020021600)&(out['Date_Hour']<=2020021623),'Pred'] = out.loc[(out['Date_Hour']>=2020021600)&(out['Date_Hour']<=2020021623),'Pred']*0.95\n",
    "    out.loc[(out['Date_Hour']>=2020022100)&(out['Date_Hour']<=2020022123),'Pred'] = out.loc[(out['Date_Hour']>=2020022100)&(out['Date_Hour']<=2020022123),'Pred']*1.02\n",
    "    out.loc[(out['Date_Hour']>=2020022400)&(out['Date_Hour']<=2020022423),'Pred'] = out.loc[(out['Date_Hour']>=2020022400)&(out['Date_Hour']<=2020022423),'Pred']*1.05\n",
    "    out.to_csv('LC.csv',header=None,sep=',',index=False)\n",
    "\n",
    "solve3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20833643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
